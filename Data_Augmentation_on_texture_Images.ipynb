{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Augmentation on texture Images.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fm5wmwZAUWg4LK4HgTZ4cjF0VktDJukf",
      "authorship_tag": "ABX9TyMfCBlnKObexEsxDgcdr26G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neeluvermaiitj/Data-Augmentation-on-Texture-Images-to-create-dataset/blob/main/Data_Augmentation_on_texture_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFqT-kBFIIgm"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O4uQR2JYsSf"
      },
      "source": [
        "Ill1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FJnTSvnxslf"
      },
      "source": [
        "\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load origional the image\n",
        "img1 = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resize/Cr_241.bmp')\n",
        "img2 = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resize/Sc_241.bmp')\n",
        "img3 = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resize/RS_241.bmp')\n",
        "img4 = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resize/PS_241.bmp')\n",
        "img5 = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resize/Pa_241.bmp')\n",
        "img6 = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resize/In_241.bmp')\n",
        "\n",
        "i=1\n",
        "figure= pyplot.figure(figsize=(20, 20))\n",
        "for img in [img1, img2, img3, img4,img5, img6]:\n",
        "# # show the figure\n",
        "  # pyplot.show()\n",
        "  data = img_to_array(img)\n",
        "  # expand dimension to one sample\n",
        "  samples = expand_dims(data, 0)\n",
        "  # create image data augmentation generator\n",
        "  datagen = ImageDataGenerator(brightness_range=[-1.0,1.0])\n",
        "  # prepare iterator\n",
        "  it = datagen.flow(samples, batch_size=1)\n",
        "  # generate samples and plot\n",
        "  \n",
        "  # define subplot\n",
        "  figure.add_subplot(1, 6, i)\n",
        "  # pyplot.subplot(330 + 1 + i)\n",
        "  # generate batch of images\n",
        "  batch = it.next()\n",
        "  # convert to unsigned integers for viewing\n",
        "  image = batch[0].astype('uint8')\n",
        "  # plot raw pixel data\n",
        "  pyplot.imshow(image)\n",
        "  i+=1\n",
        "  # show the figure\n",
        "pyplot.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4CaQ51dZoiy"
      },
      "source": [
        "#scratches\n",
        "\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load the image\n",
        "img = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resize/*')\n",
        "# convert to numpy array\n",
        "data1 = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "samples = expand_dims(data1, 0)\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(brightness_range=[-1,1])\n",
        "# prepare iterator\n",
        "it = datagen.flow(samples)\n",
        "batch = it.next()\n",
        "\t# convert to unsigned integers for viewing\n",
        "image = batch[0].astype('uint8')\n",
        "\t# plot raw pixel data\n",
        "\n",
        "pyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xE_M6WCaMOc"
      },
      "source": [
        "#rolled-in_scale\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load the image\n",
        "img = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resize/RS_241.bmp')\n",
        "# convert to numpy array\n",
        "data = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "samples = expand_dims(data, 0)\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(brightness_range=[-1,1])\n",
        "# prepare iterator\n",
        "it = datagen.flow(samples, batch_size=1)\n",
        "batch = it.next()\n",
        "\t# convert to unsigned integers for viewing\n",
        "image = batch[0].astype('uint8')\n",
        "\t# plot raw pixel data\n",
        "pyplot.imshow(image)\n",
        "\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkSDWeskZxRe"
      },
      "source": [
        "#pitted_surface\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load the image\n",
        "img = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resizeIll1/pitted_surface_241-1.jpg')\n",
        "# convert to numpy array\n",
        "data = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "samples = expand_dims(data, 0)\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(brightness_range=[-1,1])\n",
        "# prepare iterator\n",
        "it = datagen.flow(samples, batch_size=1)\n",
        "batch = it.next()\n",
        "\t# convert to unsigned integers for viewing\n",
        "image = batch[0].astype('uint8')\n",
        "\t# plot raw pixel data\n",
        "\n",
        "pyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZs5IB-NagdW"
      },
      "source": [
        "#inclusion\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load the image\n",
        "img = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resizeIll1/inclusion_241-1.jpg')\n",
        "# convert to numpy array\n",
        "data = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "samples = expand_dims(data, 0)\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(brightness_range=[-1,1])\n",
        "# prepare iterator\n",
        "it = datagen.flow(samples, batch_size=1)\n",
        "batch = it.next()\n",
        "\t# convert to unsigned integers for viewing\n",
        "image = batch[0].astype('uint8')\n",
        "\t# plot raw pixel data\n",
        "pyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dBnN78ubUTN"
      },
      "source": [
        "#patches\n",
        "\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load the image\n",
        "img = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resizeIll1/patches_241-1.jpg')\n",
        "# convert to numpy array\n",
        "data = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "samples = expand_dims(data, 0)\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(brightness_range=[-1,1])\n",
        "# prepare iterator\n",
        "it = datagen.flow(samples, batch_size=1)\n",
        "pyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYnCrdkbZCRq"
      },
      "source": [
        "#inclusion\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load the image\n",
        "img = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resizeIll1/inclusion_241-1.jpg')\n",
        "# convert to numpy array\n",
        "data = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "samples = expand_dims(data, 0)\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(brightness_range=[-1,1])\n",
        "# prepare iterator\n",
        "it = datagen.flow(samples, batch_size=1)\n",
        "pyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdUd2-48b5tL"
      },
      "source": [
        "# Ill0.4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9cSMaG_r80m"
      },
      "source": [
        "#crazing\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load the image\n",
        "img = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resizeIll0.4/crazing_241-1.jpg')\n",
        "# convert to numpy array\n",
        "data = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "samples = expand_dims(data, 0)\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(brightness_range=[-1,1])\n",
        "# prepare iterator\n",
        "it = datagen.flow(samples, batch_size=1)\n",
        "\n",
        "pyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjPA6KORcokG"
      },
      "source": [
        "#scratches images_resizeIll0.4\n",
        "\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load the image\n",
        "img = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resizeIll0.4/crazing_241-1.jpg')\n",
        "# convert to numpy array\n",
        "data = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "samples = expand_dims(data, 0)\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(brightness_range=[-1,1])\n",
        "# prepare iterator\n",
        "it = datagen.flow(samples, batch_size=1)\n",
        "pyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP14KEkidB_M"
      },
      "source": [
        "#rolled-in_scale\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load the image\n",
        "img = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resizeIll0.4/rolled-in_scale_241-1.jpg')\n",
        "# convert to numpy array\n",
        "data = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "samples = expand_dims(data, 0)\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(brightness_range=[-1,1])\n",
        "# prepare iterator\n",
        "it = datagen.flow(samples, batch_size=1)\n",
        "pyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAASQaOKdPQ0"
      },
      "source": [
        "#pitted_surface\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load the image\n",
        "img = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resizeIll0.4/rolled-in_scale_241-1.jpg')\n",
        "# convert to numpy array\n",
        "data = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "samples = expand_dims(data, 0)\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(brightness_range=[-1,1])\n",
        "# prepare iterator\n",
        "it = datagen.flow(samples, batch_size=1)\n",
        "pyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGRLNTuIdwwt"
      },
      "source": [
        "#inclusion\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load the image\n",
        "img = load_img('/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resizeIll0.4/rolled-in_scale_241-1.jpg')\n",
        "\n",
        "# convert to numpy array\n",
        "data = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "samples = expand_dims(data, 0)\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(brightness_range=[-1,1])\n",
        "# prepare iterator\n",
        "it = datagen.flow(samples, batch_size=1)\n",
        "\n",
        "pyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCO2y5NNcjnc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND7VrS14eeir"
      },
      "source": [
        "# Motion_blur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SN7H66agi8k"
      },
      "source": [
        "Lcm=2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bqQhUFTwuKP"
      },
      "source": [
        "# motion blur on crazing degree=2, angle\n",
        "\n",
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "path='/content/drive/MyDrive/Colab Notebooks/DAI_project/elpv_dataset/train_test_images/test25'\n",
        "def motion_blur(image, degree=2):\n",
        "    image = np.array(image)\n",
        "    angle = random.randint(0,360)\n",
        "    # This generates a matrix of motion blur kernels at any angle. The greater the degree, the higher the blur.\n",
        "    M = cv2.getRotationMatrix2D((degree / 2, degree / 2), angle, 1)\n",
        "    motion_blur_kernel = np.diag(np.ones(degree))\n",
        "    motion_blur_kernel = cv2.warpAffine(motion_blur_kernel, M, (degree, degree))\n",
        "\n",
        "    motion_blur_kernel = motion_blur_kernel / degree\n",
        "    blurred = cv2.filter2D(image, -1, motion_blur_kernel)\n",
        "\n",
        "    # convert to uint8\n",
        "    cv2.normalize(blurred, blurred, 0, 255, cv2.NORM_MINMAX)\n",
        "    blurred = np.array(blurred, dtype=np.uint8)\n",
        "    return blurred\n",
        "for img_name in os.listdir(path):\n",
        "  img = cv2.imread(os.path.join(path,img_name))\n",
        "  blurred_img = motion_blur(img)\n",
        "  cv2.imwrite(os.path.join(path+'blurred2',img_name ), blurred_img)\n",
        "  print(img_name)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(blurred_img)\n",
        "cv2.waitKey()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbq6rJn8IclS"
      },
      "source": [
        "# motion blur on crazing degree=2, angle\n",
        "\n",
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "path='/content/drive/MyDrive/Colab Notebooks/DAI_project/elpv_dataset/train_test_images/test25'\n",
        "def motion_blur(image, degree=2):\n",
        "    image = np.array(image)\n",
        "    angle = random.randint(0,360)\n",
        "    # This generates a matrix of motion blur kernels at any angle. The greater the degree, the higher the blur.\n",
        "    M = cv2.getRotationMatrix2D((degree / 2, degree / 2), angle, 1)\n",
        "    motion_blur_kernel = np.diag(np.ones(degree))\n",
        "    motion_blur_kernel = cv2.warpAffine(motion_blur_kernel, M, (degree, degree))\n",
        "\n",
        "    motion_blur_kernel = motion_blur_kernel / degree\n",
        "    blurred = cv2.filter2D(image, -1, motion_blur_kernel)\n",
        "\n",
        "    # convert to uint8\n",
        "    cv2.normalize(blurred, blurred, 0, 255, cv2.NORM_MINMAX)\n",
        "    blurred = np.array(blurred, dtype=np.uint8)\n",
        "    return blurred\n",
        "for img_name in os.listdir(path):\n",
        "  img = cv2.imread(os.path.join(path,img_name))\n",
        "  blurred_img = motion_blur(img)\n",
        "  cv2.imwrite(os.path.join(path+'blurred',img_name ), blurred_img)\n",
        "  print(img_name)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(blurred_img)\n",
        "cv2.waitKey()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZOGDrtzCTKZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNl-nvrLCXBp"
      },
      "source": [
        "# Lcm=2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqwDOEt4CDjb"
      },
      "source": [
        "# motion blur on origional images degree=2, angle=0 to 360\n",
        "\n",
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "# path='/content/drive/MyDrive/Colab Notebooks/DAI_project/elpv_dataset/train_test_images/test25'\n",
        "path= '/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resize/'\n",
        "def motion_blur(image, degree=2):\n",
        "    image = np.array(image)\n",
        "    angle = random.randint(0,360)\n",
        "    # This generates a matrix of motion blur kernels at any angle. The greater the degree, the higher the blur.\n",
        "    M = cv2.getRotationMatrix2D((degree / 2, degree / 2), angle, 1)\n",
        "    motion_blur_kernel = np.diag(np.ones(degree))\n",
        "    motion_blur_kernel = cv2.warpAffine(motion_blur_kernel, M, (degree, degree))\n",
        "\n",
        "    motion_blur_kernel = motion_blur_kernel / degree\n",
        "    blurred = cv2.filter2D(image, -1, motion_blur_kernel)\n",
        "\n",
        "    # convert to uint8\n",
        "    cv2.normalize(blurred, blurred, 0, 255, cv2.NORM_MINMAX)\n",
        "    blurred = np.array(blurred, dtype=np.uint8)\n",
        "    return blurred\n",
        "for img_name in os.listdir(path):\n",
        "  img = cv2.imread(os.path.join(path,img_name))\n",
        "  blurred_img = motion_blur(img)\n",
        "  cv2.imwrite(os.path.join(path+'blurred',img_name ), blurred_img)\n",
        "  print(img_name)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(blurred_img)\n",
        "cv2.waitKey()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7bjsJIXgn8e"
      },
      "source": [
        "# Lcm = 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLuk0c18HmBd"
      },
      "source": [
        "# motion blur on crazing degree=2, angle\n",
        "\n",
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "# path='/content/drive/MyDrive/Colab Notebooks/DAI_project/elpv_dataset/train_test_images/test25'\n",
        "path= '/content/drive/MyDrive/Colab Notebooks/DAI_project/images_preprocessed/images_resize/'\n",
        "def motion_blur(image, degree=5):\n",
        "    image = np.array(image)\n",
        "    angle = random.randint(0,360)\n",
        "    # This generates a matrix of motion blur kernels at any angle. The greater the degree, the higher the blur.\n",
        "    M = cv2.getRotationMatrix2D((degree / 2, degree / 2), angle, 1)\n",
        "    motion_blur_kernel = np.diag(np.ones(degree))\n",
        "    motion_blur_kernel = cv2.warpAffine(motion_blur_kernel, M, (degree, degree))\n",
        "\n",
        "    motion_blur_kernel = motion_blur_kernel / degree\n",
        "    blurred = cv2.filter2D(image, -1, motion_blur_kernel)\n",
        "\n",
        "    # convert to uint8\n",
        "    cv2.normalize(blurred, blurred, 0, 255, cv2.NORM_MINMAX)\n",
        "    blurred = np.array(blurred, dtype=np.uint8)\n",
        "    return blurred\n",
        "for img_name in os.listdir(path):\n",
        "  img = cv2.imread(os.path.join(path,img_name))\n",
        "  blurred_img = motion_blur(img)\n",
        "  cv2.imwrite(os.path.join(path+'blurred5',img_name ), blurred_img)\n",
        "  print(img_name)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(blurred_img)\n",
        "cv2.waitKey()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}